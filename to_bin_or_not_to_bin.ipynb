{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 76728,
          "databundleVersionId": 9057646,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "to_bin_or_not_to_bin",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OleksiiLatypov/Regression_of_Used_Car_Prices/blob/main/to_bin_or_not_to_bin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e9:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F76728%2F9057646%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240917%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240917T204145Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db3065a143da210d12640a46d1ff1f2e156f3cac8c326ef9460c3c596dfb9276ec6329be9920dcaa3f36299b5394cf70fbc4a168b9d0903c8b6c990164a3db41497545f7ece75191e46be15816e0d375b29da86d988e209cb4fce085f6144f06c154e1378fdd17cd664a1eecc18969e8721076fe3ebddcabb7b80702f4d4b004dd2adc8e8deef15db81606e0ee1b9c84596a868934b913effb6c610cd002e0b7f45ff1ab40e3c93828e2ff6369bc03dbde92d3f55e2a4c08296e644fa330209e034ac59eb0fce891945bfd5d8275b96a8bbec68d2bc3d67a50422052f79ca4ed25e47877d33d691cee3b51f5dc201d7e9e805b0d8d108ea6b4d80d5c3cc9d92b0'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "qdJQmWmauEi5"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from scipy import stats\n",
        "from scipy.special import inv_boxcox\n",
        "from datetime import datetime\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import Lasso, Ridge, SGDRegressor, LinearRegression\n",
        "import category_encoders as ce\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "e9v0LZvHuEi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "nCYGTe7GuEi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "q_hARV4XuEi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "rlLccTdQuEi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(np.log(train['price']), kde=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "psCAh4LyuEi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concate"
      ],
      "metadata": {
        "id": "d7PnXWNZuEi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenate train and test datasets along rows to form a single DataFrame for preprocessing.\n",
        "This approach allows us to apply consistent transformations (e.g., encoding, scaling) to both\n",
        "train and test data at the same time, ensuring no discrepancies between them.\n",
        "`ignore_index=True` is used to reset the index and avoid duplicated indices from the original datasets."
      ],
      "metadata": {
        "id": "E893dGnGuEi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([train, test], axis=0, ignore_index=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0Xl69UI-uEi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the 'id' column from the DataFrame as it is not relevant for the prediction task."
      ],
      "metadata": {
        "id": "HMNT0y7puEi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('id', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dNoVOUlsuEi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# price, price_lambda = stats.boxcox(train['price'])\n",
        "# print(price_lambda)\n",
        "# milage, milage_lambda = stats.boxcox(train['milage'])\n",
        "# print(milage_lambda)\n",
        "# age, age_lambda = stats.boxcox(datetime.now().year - train['model_year'] + 1)\n",
        "# print(age_lambda)"
      ],
      "metadata": {
        "trusted": true,
        "id": "p-1k73BRuEi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for duplicates"
      ],
      "metadata": {
        "id": "aFs3z53xuEi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = df.duplicated()\n",
        "duplicates.any()"
      ],
      "metadata": {
        "trusted": true,
        "id": "EOUf9qVtuEi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['price'] = price\n",
        "# df['age'] = age\n",
        "# df['milage'] = milage\n",
        "# df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Fo-UsHFAuEi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group the training data by 'brand' and calculate both the mean and median prices for each car brand.\n",
        "This helps identify the most expensive brands in terms of price, as both metrics provide insights:\n",
        "- 'mean' shows the average price per brand, which can be skewed by outliers.\n",
        "- 'median' gives a more robust central tendency, less affected by extreme values.\n",
        "The results are then sorted by 'median' price in descending order to highlight the top luxury car brands."
      ],
      "metadata": {
        "id": "E80xkgTiuEi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lux_car = train.groupby(['brand'])['price'].agg(['mean', 'median'])\n",
        "lux_car.sort_values(by='median', ascending=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dbIYQ0jPuEi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define price bins and corresponding labels to categorize the cars into different price ranges.\n",
        "Bins are specified to capture a range from affordable to luxury car prices, with the upper limit covering high-end cars.\n",
        "The 'pd.cut()' function assigns each car in the 'price' column to one of the categories based on the defined bins.\n",
        "'include_lowest=True' ensures that the lowest price falls into the first bin."
      ],
      "metadata": {
        "id": "wJ5pDZD8uEi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "price_bins = [0, 15000, 25000, 40000, 70000, 300000]  # Adjust based on your price distribution\n",
        "price_labels = [0, 1, 3, 4, 5]\n",
        "\n",
        "# Bin the brands based on their median prices using pd.cut\n",
        "lux_car['price_category'] = pd.cut(lux_car['median'], bins=price_bins, labels=price_labels, include_lowest=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "o_zzjU5juEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brand_to_price_category = lux_car['price_category'].to_dict()\n",
        "df['price_category'] = df['brand'].map(brand_to_price_category)\n",
        "df['price_category'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "CWjIW-WtuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'] = datetime.now().year - df['model_year']\n",
        "df = df.drop('model_year', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "H6Dck1_RuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "NclTuutXuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lux_auto = [\n",
        "    \"Mercedes-Benz\",\n",
        "    \"Audi\",\n",
        "    \"BMW\",\n",
        "    \"Tesla\",\n",
        "    \"Cadillac\",\n",
        "    \"Land Rover\",\n",
        "    \"Porsche\",\n",
        "    \"Lexus\",\n",
        "    'Genesis',\n",
        "    \"INFINITI\",\n",
        "    \"Jaguar\",\n",
        "    \"Rolls-Royce\",\n",
        "    \"Bentley\",\n",
        "    \"Ferrari\",\n",
        "    \"Aston Martin\",\n",
        "    \"Lamborghini\",\n",
        "    \"Bugatti\",\n",
        "    \"Maserati\",\n",
        "    \"Lucid\",\n",
        "    \"Polestar\",\n",
        "    \"Maybach\",\n",
        "    \"Lincoln\"\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "id": "2c8s30dNuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['premium_auto'] = df['brand'].apply(lambda x: 1 if x in lux_auto else 0)\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "wzTjnfLCuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = df.iloc[:188533, :].select_dtypes(include=['number'])\n",
        "correlation = num.corr()\n",
        "sns.heatmap(correlation, annot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "N5tW2ft4uEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "horsepower = []\n",
        "engine_volume = []\n",
        "num_of_cylinders = []\n",
        "for col in df['engine']:\n",
        "    hp = re.search(r'(\\d+\\.?\\d*)HP', col, re.IGNORECASE)\n",
        "    #print(hp)\n",
        "    if hp:\n",
        "        horsepower.append(float(hp.group(1)))\n",
        "    else:\n",
        "        horsepower.append(0)\n",
        "\n",
        "    volume = re.search(r'(\\d+\\.?\\d*)L|(\\d+\\.?\\d*\\s*)Liter', col, re.IGNORECASE)\n",
        "    if volume:\n",
        "        if volume.group(1):\n",
        "            engine_volume.append(float(volume.group(1)))\n",
        "        elif volume.group(2):\n",
        "            engine_volume.append(float(volume.group(2)))\n",
        "    else:\n",
        "        engine_volume.append(0)\n",
        "\n",
        "    cylinder = re.search(r'(\\d+)\\s*Cylinder|V(\\d+)|I(\\d+)', col, re.IGNORECASE)\n",
        "\n",
        "    if cylinder:\n",
        "        # If we find a numeric cylinder, use that\n",
        "        if cylinder.group(1):\n",
        "            num_of_cylinders.append(float(cylinder.group(1)))\n",
        "        # If we find a V-style code, use the number after 'V'\n",
        "        elif cylinder.group(2):\n",
        "            num_of_cylinders.append(float(cylinder.group(2)))\n",
        "        elif cylinder.group(3):\n",
        "            num_of_cylinders.append(float(cylinder.group(3)))\n",
        "    else:\n",
        "        # If no match is found, default to 0\n",
        "        num_of_cylinders.append(0)\n",
        "\n",
        "print(len(horsepower))\n",
        "print(len(engine_volume))\n",
        "print(len(num_of_cylinders))\n",
        "df['horsepower'] = horsepower\n",
        "df['engine_volume'] = engine_volume\n",
        "df['num_of_cylinders'] = num_of_cylinders\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "cECYe1gmuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['num_of_cylinders'] == 0]['engine'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ophwlHhIuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mode of the 'num_of_cylinders' column\n",
        "mode_cylinders = df['num_of_cylinders'].mode()[0]\n",
        "print(mode_cylinders)\n",
        "\n",
        "# Use a conditional mask to filter rows where 'num_of_cylinders' is 0 and 'engine' does not contain 'Electric'\n",
        "mask = (df['num_of_cylinders'] == 0) & (~df['engine'].str.contains('Electric'))\n",
        "\n",
        "# Replace 0 values with the mode for the filtered rows\n",
        "df.loc[mask, 'num_of_cylinders'] = mode_cylinders"
      ],
      "metadata": {
        "trusted": true,
        "id": "alBDGbTguEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['num_of_cylinders'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "5RkTkABTuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "100 *55440/314223"
      ],
      "metadata": {
        "trusted": true,
        "id": "OGRwWdz4uEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_replace = []\n",
        "for row in df.loc[df['fuel_type'] == 'not supported', 'engine']:\n",
        "    fuel = re.search(r'(Gasoline|Diesel|Hybrid|Flex Fuel|Electric|Plug-In Hybrid)', row)\n",
        "    if fuel.group(1) == 'Flex Fuel':\n",
        "        to_replace.append('E85 Flex Fuel')\n",
        "    else:\n",
        "        to_replace.append(fuel.group(1))\n",
        "print(to_replace)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MP3G2HlvuEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['fuel_type'] == 'not supported'][['fuel_type', 'engine']]"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wm8AnY3huEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['fuel_type'] == 'not supported', 'fuel_type'] = to_replace"
      ],
      "metadata": {
        "trusted": true,
        "id": "hW9EhX-QuEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['fuel_type'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "QFTolqC2uEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['fuel_type'] == 'not supported', 'fuel_type']"
      ],
      "metadata": {
        "trusted": true,
        "id": "6B89lUyDuEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['fuel_type'].isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "id": "J6XV9M48uEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[pd.isna(df['fuel_type'])][['fuel_type', 'engine']]"
      ],
      "metadata": {
        "trusted": true,
        "id": "7KwI3xywuEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_fuel_type(engine_str):\n",
        "\n",
        "    if 'Hybrid' in engine_str:\n",
        "        return 'Hybrid'\n",
        "    elif 'Gasoline' in engine_str:\n",
        "        return 'Gasoline'\n",
        "    elif 'Flex Fuel' in engine_str:\n",
        "        return 'E85 Flex Fuel'\n",
        "    elif 'Diesel' in engine_str or 'Dual Motor' in engine_str:\n",
        "        return 'Diesel'\n",
        "    else:\n",
        "        return 'Electric'"
      ],
      "metadata": {
        "trusted": true,
        "id": "8Sp_DTFduEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find rows where 'fuel_type' is missing\n",
        "missing_fuel = df[pd.isna(df['fuel_type'])]\n",
        "\n",
        "# Determine the type of fuel for these rows\n",
        "missing_fuel['fuel_type'] = missing_fuel['engine'].apply(determine_fuel_type)\n",
        "\n",
        "# Update the original DataFrame with the new fuel types\n",
        "df.update(missing_fuel[['fuel_type']])\n",
        "\n",
        "# Print the number of updated entries\n",
        "print(len(missing_fuel))"
      ],
      "metadata": {
        "trusted": true,
        "id": "_JXeExriuEjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['fuel_type'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "dhIyRst2uEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['fuel_type'] = df['fuel_type'].replace('–', 'Unknown')"
      ],
      "metadata": {
        "trusted": true,
        "id": "NoKfherpuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['transmission'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "0Z-vky_AuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['price'].max()"
      ],
      "metadata": {
        "trusted": true,
        "id": "1anFwLuwuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_transmission(transmission):\n",
        "    transmission = str(transmission).lower()\n",
        "    if 'manual' in transmission or 'm/t' in transmission or 'mt' in transmission:\n",
        "        return 'Manual'\n",
        "    elif 'automatic' in transmission or 'a/t' in transmission\\\n",
        "        or 'cvt' in transmission or 'variable' in transmission\\\n",
        "        or 'dct' in transmission or 'at/mt' in transmission\\\n",
        "        or 'dual' in transmission or 'at' in transmission:\n",
        "        return 'Automatic'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "    return transmission"
      ],
      "metadata": {
        "trusted": true,
        "id": "hjWen85zuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['transmission_category'] = df['transmission'].apply(categorize_transmission)\n",
        "df['transmission_category'] = df['transmission'].apply(categorize_transmission)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zPR_Z8iQuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_num_speeds(transmission_str):\n",
        "    # Regular expression to match the number of speeds\n",
        "    match = re.search(r'(\\d+)\\s*[-\\s]*Speed', transmission_str, re.IGNORECASE)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "trusted": true,
        "id": "Kk5ZIOFIuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_speed'] = df['transmission'].apply(extract_num_speeds)"
      ],
      "metadata": {
        "trusted": true,
        "id": "oduTVPetuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type_trans = []\n",
        "# for row in df['transmission']:\n",
        "#     # Ensure the row is not NaN\n",
        "#     if pd.notna(row):\n",
        "#         # Check for various transmission types\n",
        "#         if any(keyword in row for keyword in ['Automatic', 'A/T', 'AT', 'A/t', 'Transmission Overdrive Switch']):\n",
        "#             type_trans.append('A')\n",
        "#         elif 'DCT' in row:\n",
        "#             type_trans.append('DCT')\n",
        "#         elif 'Transmission w/Dual Shift Mode' in row:\n",
        "#             type_trans.append('Transmission w/Dual Shift Mode')\n",
        "#         elif 'CVT' in row or 'CVT-F' in row:\n",
        "#             type_trans.append('CVT')\n",
        "#         elif 'Variable' in row:\n",
        "#             type_trans.append('Variable')\n",
        "#         elif 'Single-Speed Fixed Gear' in row:\n",
        "#             type_trans.append('Single-Speed Fixed Gear')\n",
        "#         elif row.strip() == 'F':  # Use strip() to avoid false matches for 'F'\n",
        "#             type_trans.append('F')\n",
        "#         elif 'At/Mt' in row:\n",
        "#             type_trans.append('At/Mt')\n",
        "#         elif '–' in row:  # Handle dash case\n",
        "#             type_trans.append('Unknown')\n",
        "#         else:\n",
        "#             type_trans.append('M')  # Assume manual transmission by default\n",
        "#     else:\n",
        "#         # Handle missing or NaN values if any\n",
        "#         type_trans.append('Unknown')\n",
        "\n",
        "# # Output the unique transmission types\n",
        "# print(set(type_trans))\n",
        "#df['type_transmission'] = type_trans\n",
        "# df['num_of_speed'] = num_of_speed"
      ],
      "metadata": {
        "trusted": true,
        "id": "fG-KMS_4uEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['accident'] = df['accident'].fillna(df['accident'].mode()[0])\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "id": "aqH-4jntuEjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['accident'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "a5Sr1bkUuEjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.copy()\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "1KjajKTpuEjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_colors = df['ext_col'].str.lower().value_counts()[:10].index.tolist()\n",
        "base_colors"
      ],
      "metadata": {
        "trusted": true,
        "id": "HQ44qUrJuEjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Base colors:\", base_colors)\n",
        "\n",
        "# Function to extract and standardize colors\n",
        "def extract_colors(colors):\n",
        "    colors = str(colors).strip().lower()  # Convert to lowercase and strip whitespace\n",
        "    if colors in base_colors:\n",
        "        return colors\n",
        "    return 'other'\n",
        "\n",
        "# Apply the function to the 'ext_col' column\n",
        "df['ext_col'] = df['ext_col'].apply(extract_colors)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mUBwPGNMuEjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_color_int = df['int_col'].str.lower().value_counts()[:6].index.tolist()\n",
        "base_color_int"
      ],
      "metadata": {
        "trusted": true,
        "id": "_UAFWHXruEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_int_colors(colors):\n",
        "    colors = str(colors).lower()\n",
        "    if colors in base_color_int:\n",
        "        return colors\n",
        "    return 'other'"
      ],
      "metadata": {
        "trusted": true,
        "id": "d0-8NKo3uEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['int_col'] = df['int_col'].apply(extract_int_colors)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gyyFpCTnuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "KCSMbdlguEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['engine', 'transmission', 'clean_title'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "15YHHhVIuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['horsepower'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "eKXKVB-LuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "med_hp = round(df['horsepower'].median())\n",
        "df.loc[df['horsepower'] == 0, 'horsepower'] = round(med_hp)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "eDWNRJOJuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['horsepower'].value_counts() / df.shape[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "W_4fL1E8uEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #price, price_lambda = stats.boxcox(train['price'])\n",
        "# print(price_lambda)\n",
        "# milage, milage_lambda = stats.boxcox(df['milage'])\n",
        "# print(milage_lambda)\n",
        "# age, age_lambda = stats.boxcox(datetime.now().year - df['model_year'] + 1)\n",
        "# print(age_lambda)"
      ],
      "metadata": {
        "trusted": true,
        "id": "l8VH-5w3uEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_gf6ppOxuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['transmission_category'].str.contains('Unknown')]['transmission'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2pTNilWcuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_counts = df['model'].value_counts()\n",
        "df['model_frequency'] = df['model'].map(model_counts)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2SYLACpluEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('model', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RKFAubPyuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "VwmbcIq7uEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_encode = ['brand', 'ext_col', 'int_col', 'fuel_type', 'transmission_category']\n",
        "df_to_encode = df[columns_to_encode]\n",
        "df_encoded = pd.get_dummies(df_to_encode, columns=columns_to_encode, dtype='int')"
      ],
      "metadata": {
        "trusted": true,
        "id": "-x75yc_MuEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns_to_encode, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aeUwcLKiuEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "chVkPLGFuEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['accident'] = le.fit_transform(df['accident'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "pMmQAFaNuEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "lxYhFb7huEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.concat([df, df_encoded], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "XDeELiL1uEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "GF8XSxD8uEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = new_df.iloc[:188533, :]\n",
        "test_df = new_df.iloc[188533:, :]"
      ],
      "metadata": {
        "trusted": true,
        "id": "vqKYlriOuEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "e0jS-rPguEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = X['price']\n",
        "X = X.drop('price', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fBiGuGuWuEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-17T20:19:29.621824Z",
          "iopub.execute_input": "2024-09-17T20:19:29.622318Z",
          "iopub.status.idle": "2024-09-17T20:19:29.780809Z",
          "shell.execute_reply.started": "2024-09-17T20:19:29.622248Z",
          "shell.execute_reply": "2024-09-17T20:19:29.779654Z"
        },
        "trusted": true,
        "id": "X2jyu1FbuEjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create the pipeline\n",
        "lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Step 1: MinMax scaling\n",
        "    ('regressor', LinearRegression())  # Step 2: Linear Regression model\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f'Root Mean Squared Error: {rmse}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-17T20:41:24.212684Z",
          "iopub.execute_input": "2024-09-17T20:41:24.213783Z",
          "iopub.status.idle": "2024-09-17T20:41:26.478001Z",
          "shell.execute_reply.started": "2024-09-17T20:41:24.213735Z",
          "shell.execute_reply": "2024-09-17T20:41:26.476404Z"
        },
        "trusted": true,
        "id": "4Gdg8QMHuEjJ",
        "outputId": "5df4508b-4db8-4dca-c421-e20d972b4cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Root Mean Squared Error: 69627.90934249542\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler()),  # Step 1: MinMax scaling\n",
        "    ('regressor', KNeighborsRegressor())  # Step 2: KNeighborsRegressor model\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-17T20:41:37.229559Z",
          "iopub.execute_input": "2024-09-17T20:41:37.229955Z"
        },
        "trusted": true,
        "id": "RjE6k29HuEjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Initialize and train the model\n",
        "model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Root Mean Squared Error: {np.sqrt(mse)}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-17T20:37:47.166564Z",
          "iopub.execute_input": "2024-09-17T20:37:47.167022Z",
          "iopub.status.idle": "2024-09-17T20:38:09.402036Z",
          "shell.execute_reply.started": "2024-09-17T20:37:47.166972Z",
          "shell.execute_reply": "2024-09-17T20:38:09.400786Z"
        },
        "trusted": true,
        "id": "WRgMi9_muEjJ",
        "outputId": "7a2a9ace-6f9c-47b3-cc00-c9a6910eb6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Root Mean Squared Error: 78153.26771265175\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-17T20:24:29.863222Z",
          "iopub.execute_input": "2024-09-17T20:24:29.863674Z",
          "iopub.status.idle": "2024-09-17T20:24:29.870909Z",
          "shell.execute_reply.started": "2024-09-17T20:24:29.863629Z",
          "shell.execute_reply": "2024-09-17T20:24:29.869736Z"
        },
        "trusted": true,
        "id": "51majrxIuEjJ",
        "outputId": "3e26fb53-6ab6-49e0-98c1-851d658a63a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 239,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([34763.82035714, 16616.35      , 34723.7       , ...,\n       22046.9       , 14068.9       , 76737.36      ])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "id": "5dfgE0h4uEjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0I-aUS-uEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5A8iYmNuuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYDZdxYfuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IexLf5t_uEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Target variable\n",
        "target = 'price'\n",
        "\n",
        "# Target encoding for 'brand'\n",
        "brand_mean = train_df.groupby('brand')[target].mean()\n",
        "train_df['brand_encoded'] = train_df['brand'].map(brand_mean)\n",
        "\n",
        "\n",
        "# Target encoding for 'model'\n",
        "model_mean = train_df.groupby('model')[target].mean()\n",
        "train_df['model_encoded'] = train_df['model'].map(model_mean)\n",
        "\n",
        "# Drop original categorical columns if needed\n",
        "train_df = train_df.drop(columns=['brand', 'model'])\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WNCSMdzwuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# le = LabelEncoder()\n",
        "# train_df['accident'] = le.fit_transform(train_df['accident'])\n",
        "# test_df['accident'] = le.transform(test_df['accident'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "SXPjbhGNuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PXpg_9x0uEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['brand_model'] = df['brand'] + '_' + df['model']\n",
        "# df = pd.get_dummies(df, columns=['brand_model'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "YqwjZkg5uEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.copy()"
      ],
      "metadata": {
        "trusted": true,
        "id": "fBTDLpoluEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = X['price']\n",
        "X = X.drop('price', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Bf-jar8ouEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop('price', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gVyzo-CGuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.log(y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_YiD_q8VuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cbe_encoder = ce.cat_boost.CatBoostEncoder(a=1)\n",
        "# X_encoded = cbe_encoder.fit_transform(X, y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EovA7flVuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_encoded.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "UGB62X1LuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #for test split 0.3 is the best !!!\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "\n",
        "clf_catboost = CatBoostRegressor(iterations=700,\n",
        "                                  learning_rate=0.03,\n",
        "                                  depth=7,\n",
        "                                 l2_leaf_reg=3,\n",
        "                                border_count=254,\n",
        "                                 verbose=0)  # verbose=0 to suppress output during cross-validation\n",
        "\n",
        "\n",
        "# Define k-fold cross-validation\n",
        "n_splits = 5  # number of folds\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and evaluate RMSE\n",
        "rmse_scores = -cross_val_score(clf_catboost, X, y, scoring='neg_root_mean_squared_error', cv=kf)\n",
        "\n",
        "# Calculate mean and standard deviation of RMSE\n",
        "mean_rmse = np.mean(rmse_scores)\n",
        "std_rmse = np.std(rmse_scores)\n",
        "\n",
        "print(f\"Mean RMSE: {mean_rmse:.4f}\")\n",
        "print(f\"Standard Deviation of RMSE: {std_rmse:.4f}\")\n",
        "\n",
        "clf_catboost.fit(X, y)\n",
        "#72823 = 700iter\n",
        "#72718 = 300iter"
      ],
      "metadata": {
        "trusted": true,
        "id": "Xs9-yJkYuEjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = clf_catboost.get_feature_importance()\n",
        "feature_names = X.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(importance_df)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "dUBb5jByuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.drop('price', axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PM453im5uEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_X_encoded = cbe_encoder.transform(test_df)"
      ],
      "metadata": {
        "trusted": true,
        "id": "TATZZdxjuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_X_encoded.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "C2b9t00fuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute target encoding from training data\n",
        "test_df['brand_encoded'] = test_df['brand'].map(brand_mean)\n",
        "\n",
        "# Encode 'model' in the test data using the encoding from training data\n",
        "test_df['model_encoded'] = test_df['model'].map(model_mean)\n",
        "\n",
        "# For any values in the test data that were not seen in the training data, you may need to handle NaNs\n",
        "# test_df['brand_encoded'].fillna(test_df['brand_encoded'].mean(), inplace=True)\n",
        "# test_df['model_encoded'].fillna(test_df['model_encoded'].mean(), inplace=True)\n",
        "test_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pSqLRngguEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df['brand_encoded'].fillna(train_df['brand_encoded'].mean(), inplace=True)\n",
        "# test_df['model_encoded'].fillna(train_df['model_encoded'].mean(), inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "VTavrOU8uEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.drop(['brand', 'model'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "O8kRdTEVuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(15)"
      ],
      "metadata": {
        "trusted": true,
        "id": "NzzDSijpuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_id = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')\n",
        "predictions = clf_catboost.predict(test_df)\n",
        "test_id['price'] = np.exp(predictions)\n",
        "test_id.to_csv('submission_binning_log.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MMVJ05CQuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = clf_catboost.predict(X)[:10]\n",
        "np.exp(y_hat)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gwWx0BWuuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['price'][:10]"
      ],
      "metadata": {
        "trusted": true,
        "id": "bqhEIcsnuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MdM7LZTvuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# price, price_lambda = stats.boxcox(train['price'])\n",
        "# print(price_lambda)\n",
        "# milage, milage_lambda = stats.boxcox(train['milage'])\n",
        "# print(milage_lambda)\n",
        "# age, age_lambda = stats.boxcox(datetime.now().year - train['model_year'] + 1)\n",
        "# print(age_lambda)"
      ],
      "metadata": {
        "id": "Z_AwN8tPuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYjBGvsyuEjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Define the pipeline with preprocessing and model\n",
        "columns_to_scale = ['model_year', 'milage']\n",
        "\n",
        "# Define the preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('scaler', MinMaxScaler(), columns_to_scale)  # Apply MinMaxScaler to specified columns\n",
        "    ],\n",
        "    remainder='passthrough'  # Leave other columns unchanged\n",
        ")\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Apply preprocessing\n",
        "    ('model', KNeighborsRegressor(n_neighbors=5))  # Using KNeighborsRegressor\n",
        "])\n",
        "\n",
        "# Define k-fold cross-validation\n",
        "n_splits = 5  # number of folds\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and evaluate RMSE\n",
        "rmse_scores = -cross_val_score(pipeline, X_encoded, y, scoring='neg_root_mean_squared_error', cv=kf)\n",
        "\n",
        "# Calculate mean and standard deviation of RMSE\n",
        "mean_rmse = np.mean(rmse_scores)\n",
        "std_rmse = np.std(rmse_scores)\n",
        "\n",
        "print(f\"Mean RMSE: {mean_rmse:.4f}\")\n",
        "print(f\"Standard Deviation of RMSE: {std_rmse:.4f}\")\n",
        "\n",
        "# Fit the pipeline on the entire dataset\n",
        "pipeline.fit(X_encoded, y)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "nVpA-OIduEjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_knn = pipeline.predict(X_encoded)[:10]\n",
        "inv_boxcox(y_hat_knn, price_lambda)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hIBoTJEHuEjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}